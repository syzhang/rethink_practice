---
title: "Rethink chapter 13 practice"
output: html_notebook
---

13H1.

In 1980, a typical Bengali woman could have 5 or more children in her lifetime. By the year 2000, a typical Bengali woman had only 2 or 3. Youâ€™re going to look at a historical set of data, when contraception was widely available but many families chose not to use it.

```{r}
library(rethinking)
data(bangladesh)
d <- bangladesh
d
```
Each row is one of 1934 women. There are six variables, but you can focus on two of them for this practice problem:
(1) district: ID number of administrative district each woman resided in 
(2) use.contraception: An indicator (0/1) of whether the woman was using
contraception

The first thing to do is ensure that the cluster variable, district, is a contiguous set of integers. 

```{r}
sort(unique(d$district))
```
```{r}
d$district_id <- as.integer(as.factor(d$district))
sort(unique(d$district_id))
```

focus on predicting use.contraception, clustered by district_id. 

```{r}
dat_list <- list(
    C = d$use.contraception,
    did = d$district_id
)
```

Fit
(1) a traditional fixed-effects model that uses an index variable for district 

```{r}
m1 <- ulam(
    alist(
        C ~ bernoulli( p ),
        logit(p) <- a[did],
        a[did] ~ normal( 0 , 1 )
    ) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE , cmdstan=TRUE )
```
(2) a multilevel model with varying intercepts for district. 

```{r}
m2<- ulam(
    alist(
        C ~ bernoulli( p ),
        logit(p) <- a[did],
        a[did] ~ normal( a_bar , a_sigma),
        a_bar ~ normal(0, 1),
        a_sigma ~ exponential( 1 )
    ) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE , cmdstan=TRUE )
```
check fitting stats

```{r}
precis(m1, 2)
```
```{r}
precis(m2, 2)
```
Slightly lower n_eff in m2, more constraints?

Plot the predicted proportions of women in each district using contraception. That is, make a plot in which district ID is on the horizontal axis and expected proportion using contraception is on the vertical.

Extract posterior samples
```{r}
post1 <- extract.samples( m1 )
post2 <- extract.samples( m2 )
```

take the mean of samples (logit needs to be reversed)
```{r}
p1 <- apply( inv_logit(post1$a) , 2 , mean )
p2 <- apply( inv_logit(post2$a) , 2 , mean )
```

blue dots are fixed effect model, black ones are partial pooling model, dashline is the partial pooling model parameter a_bar

```{r}
nd <- max(dat_list$did)
plot( NULL , xlim=c(1,nd) , ylim=c(0,1) , ylab="prob use contraception" , 
    xlab="district" )
points( 1:nd , p1 , pch=16 , col=rangi2 )
points( 1:nd , p2 )
abline( h=mean(inv_logit(post2$a_bar)) , lty=2 )
```
How do the models disagree? Can you explain the pattern of disagreement? 
- In general, partial pooling model predictions shrunk towards the mean.

In particular, can you explain the most extreme cases of disagreement, both why they happen where they do and why the models reach different inferences?
- If we look at samples from each district,

```{r}
table(d$district_id)
```
e.g. district 3 has only 2 samples, the difference between the 2 models for this district is relatively larger. District 1 has a large number of samples, and the predictions are very similar. 
District 49 also has only 4 samples, but the prediction differences aren't that big, partly because the actual number is not that far from the mean.

